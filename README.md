# ProBLASTr
Pipeline which searches for homolog proteins based of protein sequences. The `run_problaster_pipeline` is the main function that runs through the 6 following steps.

## Step 1: Run BLAST Searches
First it reads in the `index.csv` file as a mapping of the genome to gff map. It then calls `makeblastdb -in genome_file -dbtype "nucl" -out db_name` with `genome_name + "_blast_db"` to create blast databases which it then searches with `tblastn -query query_file -db db_name -out output_file -evalue evalue -outfmt "6 qseqid sseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore"` with outputfile being `query_name + "_vs_" + genome_name + "_blast_hits.tsv"`. The result is saved to `output_file` and an index is saved as `blast_search_mapping.csv`.

## Step 2: Finding Annotated Genes Corresponding to tBLASTn Hits
The Blast hit generated by tBLASTn is read in and the target genome of each BLAST hit is extracted from the file name. It corresponding gff3 file is then looked up in the genome to gff mapping. The gff file is read in and filtered to include only "mRNA" and "transcript" in the column `type`. The `find_gene_from_blast_hit()` function is called with the blast_hit and the corresponding gff file, which reads in the blast_hit row for row. If the blast sequence start is lower than the blast sequence end the gff file is filtered to include only rows where the gene end is greater or equal to the blast sequence start and the gene start is lower or equal to the blast sequence start. Otherwise the gff file is filtered to include only the gene end greater or equal to the blast sequence end and gene start lower or equal to the blast sequence start. The resulting gff values are added to the blast_hit dataframe by the column `sseqid` and these gene hits are then saved as `query_name + "matches_in_" target_genome + ".csv"`. An index is saved as `gene_identification_mapping.csv`.

## Step 3: Extraction and Translating gene sequences
The indexing tables from the preceding steps are joined together and are then read in row-for-row to extract gene hit (blast hit with matching gff data), gff path and genome path.
The unique `transcript_id`, `qseqid`, `seqid`, `seqid`, `gstart`, `gend` are extracted from the dataframe gene hit and grouped by `gname`. From the `gname` column the string between "ID=" and the first ";" is extracted as transcript_id and the before corresponding before mentioned columns get added to a `transcript_info` dataframe. The `gene_seq_to_prot()` function is called for each row of the `transcript_info` dataframe. The corresponding gff file is read in and filtered by the column `type` to contain only "CDS" and the column `Parent` to contain only "transcript_id". The gff file containing now only the matching coding sequences is then sorted based on the strand type: decreasing if the strand is reverse, otherwise increasing. This is then used as a basis to extract matching sequences from the matching genome. `chr` is used as `seqnames`, and the start and end values as start and end points. If a strand is reverse in the gff it is read in as reverse. These extracted sequences are thus read in with the Biostrings `translate`function with the argument `no.init.codon = FALSE` to translate regardless of start codon and `if.fuzzy.coden = "solve"` to, upon encountering an ambiguous nucleotide, look at it and try to figure out what it means. If all possible interpretation lead to the same amino acid it will translate it as such. If all lead to a stop codon ("\*") it will translate it as such. If there are multiple options an "X" will be used instead. After the translation the protein gets cut up to before a stop codon (first "\*"). The corresponding gene name gets extracted from the gff file and writen into the header as such: `">" + gene_name + " | Source: " + genome_name + " | Reference: " + gene_hit + " | seqid: " seqid` and the file is saved as `gene_name + "_" + genome_name + "_protein.fasta"`. The full transcript is saved as well. The index information is saved to `protein_sequence_mapping.csv`.

## Step 4: Filter Sequences by Pairwise Alignment and Generate Multiple Sequence Alignments
Based of the indexing, the function `pairwise_align_protein_sequences_and_score()` is called for each query and in that loop for each matching protein file. It reads in the query file. If there are multiple sequences in the query file it only reads in the first. The subject protein and BLOSUM62 data is read in as well. The query and the subject protein sequence are pairwise aligned by using BLOSUM62 as substitution matrix, a gap opening cost of -10, gap extension cost of -0.5 and `type = "global"` to completely align both sequences. This is then given a score and the percentage identity is calculated. The alignment is saved. A logical column `passed_filter` is added based of the value of the arguments `min_score_threshold` as minimum score threshold and `min_pid_threshold` as minimum percentage identity threshold. A Scatterplot for each query with all the protein alignment is made plotting percentage identity against the pairwise alignment score and saved.
If there are more than 2 protein sequences a multiple sequence alignment is generated with the proteins that passed the filter. This MSA is not split by sequence ID. The results of the sequence filtering are saved to `sequence_filtering_results.csv` and the results of the MSA is saved to `multiple_alignment_mapping.csv`.

## Step 5: Combining Pipeline Results
A dataframe is generated combining the results of the previous steps and saved to `problaster_complete_pipeline_results.csv`.

## Step 6: Create Phylogenetic Trees
There is the option to generate phylogenetic trees for each query proteine sequence split by `seqid`'s. The function `create_phylogenetic_trees(df, min_sequences)` is called. It filteres the dataframe to include only rows that passed the threshold set by the pairwise alignment in step 4. From these, for each distinct query protein sequence (if there are more than the set minimum sequence) the `create_query_tree()` function is called. It Aligns the proteins sequences using the MUSCLE algorithm, builds a tree using Neighbor-Joining and roots the tree. The tree is saved in the newick format. The tree is also plotted with clean tip labels using the function `clean_tip_label()` and ggtree to build a circular tree with an 340 Â° open angle. The plot is also saved. 
Lastly a pipeline summary is created and saved as `pipeline_summary.csv`. The `run_problaster_pipeline()` finally returns the `problaster_complete_pipeline_results` dataframe.